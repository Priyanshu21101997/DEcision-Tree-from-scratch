{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree function to implement tree\n",
    "def DecisionTree(x,y,features,z,level):\n",
    "    len_y=len(y)\n",
    "    n_classes=len(Counter(y))\n",
    "    most_common=Counter(y).most_common(n_classes)\n",
    "    currententropy=0\n",
    "    #Here is calculation  of current entropy\n",
    "    for i in range(n_classes):\n",
    "        currententropy+=-((most_common[i][1]/len_y)*mt.log(most_common[i][1]/len_y))\n",
    "        currententropy=float(currententropy)\n",
    "    # BASE CASE  \n",
    "    if currententropy==0.0 or len(Counter(y))==0:\n",
    "        print(\"level =\",level)\n",
    "        print(\"count of\",most_common[0][0],\"=\",most_common[0][1])\n",
    "        print(\"Current Entropy =\",currententropy)\n",
    "        print(\"Reached leaf node\")\n",
    "        print()\n",
    "        return\n",
    "    elif len(features)-1==0:\n",
    "        print(\"level =\",level)\n",
    "        for i in range(n_classes):\n",
    "            print(\"count of \",most_common[i][0],\"=\",most_common[i][1])\n",
    "        print(\"Current Entropy =\",currententropy) \n",
    "        print()\n",
    "        return\n",
    "    max_gain=0\n",
    "    per_c=[]\n",
    "    per_d=[]\n",
    "    for f in features:\n",
    "        n1=x[:,f]\n",
    "        n1.sort()\n",
    "        len_n1=len(Counter(n1)) # continuous values on which split can happen\n",
    "        a=Counter(n1).most_common(len_n1)\n",
    "        for j in range(len_n1-1):\n",
    "            array_c=[]\n",
    "            array_d=[]\n",
    "            array_g=[]\n",
    "            array_h=[]\n",
    "            b=(a[j][0]+a[j+1][0])/2 # Center point of values\n",
    "            for i in range(x.shape[0]):\n",
    "                # creating nodes\n",
    "                if(x[i,f]>b):\n",
    "                    array_c.append(y[i])\n",
    "                    array_g.append(x[i,0:4])\n",
    "                else:\n",
    "                    array_d.append(y[i])\n",
    "                    array_h.append(x[i,0:4])\n",
    "            # Here we find max gain for the split         \n",
    "            if  max_gain <  gain_ratio(array_c,array_d,currententropy) :\n",
    "                splitf=f\n",
    "                max_gain= gain_ratio(array_c,array_d,currententropy)\n",
    "                per_c=array_c\n",
    "                per_d=array_d\n",
    "                newdata1=array_g\n",
    "                newdata2=array_h\n",
    "    print(\"level =\",level)            \n",
    "    out_len=len(Counter(per_c))\n",
    "    out_class=Counter(per_c).most_common(out_len)\n",
    "    for i in range(out_len):\n",
    "        print(\"count of \",out_class[i][0],\"=\",out_class[i][1])\n",
    "    print(\"current entropy=\",currententropy)\n",
    "    print(\"gain=\",max_gain)\n",
    "    print(\"split feature\",splitf)\n",
    "    print()\n",
    "    features.remove(splitf)\n",
    "    left_x=np.array(newdata2) #left node\n",
    "    left_y=np.array(per_d)\n",
    "    if(z==0):\n",
    "        z=1\n",
    "        DecisionTree(left_x,left_y,features,z,level)\n",
    "    right_x=np.array(newdata1) #right node\n",
    "    right_y=np.array(per_c)\n",
    "    level+=1\n",
    "    if(z==1):\n",
    "        z=0\n",
    "        DecisionTree(right_x,right_y,features,z,level)\n",
    "         \n",
    "\n",
    "             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gain ratio in this function :-\n",
    "def gain_ratio(c,d,rg_info):\n",
    "    m=len(c) # To find no of elements after split \n",
    "    n=len(d)\n",
    "    len_c=len(Counter(c)) # Different class and their count after the split\n",
    "    most_common_c=Counter(c).most_common(len_c)\n",
    "    most_common_c.sort()\n",
    "    info_c=0\n",
    "    # Here we calculate information gain after splitting\n",
    "    for k in range(len_c):\n",
    "        info_c+=((most_common_c[k][1])/m)*mt.log((most_common_c[k][1])/m)\n",
    "    info_c=-(info_c) \n",
    "    \n",
    "    len_d=len(Counter(d))\n",
    "    most_common_d=Counter(d).most_common(len_d)\n",
    "    most_common_d.sort()\n",
    "    info_d=0\n",
    "    for k in range(len_d):\n",
    "        info_d+=((most_common_d[k][1])/n)*mt.log((most_common_d[k][1])/n)\n",
    "    info_d=-(info_d)\n",
    "    information = ((m*info_c) +(n*info_d))/(m+n)\n",
    "    information_gain = rg_info - information\n",
    "    # Splitting no. for the two nodes after the split\n",
    "    split_no = (m*mt.log(m/m+n)+n*mt.log(n/m+n))/(m+n)\n",
    "    return information_gain /split_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level = 0\n",
      "root node\n",
      "count of  0 = 50\n",
      "count of  1 = 50\n",
      "count of  2 = 50\n",
      "\n",
      "level = 1\n",
      "count of  1 = 50\n",
      "count of  2 = 50\n",
      "current entropy= 1.0986122886681096\n",
      "gain= 0.16202302121553608\n",
      "split feature 2\n",
      "\n",
      "level = 1\n",
      "count of 0 = 50\n",
      "Current Entropy = 0.0\n",
      "Reached leaf node\n",
      "\n",
      "level = 2\n",
      "count of  2 = 50\n",
      "count of  1 = 1\n",
      "current entropy= 0.6931471805599453\n",
      "gain= 0.16461838276968993\n",
      "split feature 0\n",
      "\n",
      "level = 2\n",
      "count of 1 = 49\n",
      "Current Entropy = 0.0\n",
      "Reached leaf node\n",
      "\n",
      "level = 3\n",
      "count of  2 = 46\n",
      "current entropy= 0.09650896073594732\n",
      "gain= 0.0267173872329064\n",
      "split feature 3\n",
      "\n",
      "level = 3\n",
      "count of  2 = 4\n",
      "count of  1 = 1\n",
      "Current Entropy = 0.5004024235381879\n",
      "\n",
      "level = 4\n",
      "count of 2 = 46\n",
      "Current Entropy = 0.0\n",
      "Reached leaf node\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math as mt\n",
    "from collections import Counter\n",
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "features=[0,1,2,3]\n",
    "level=0\n",
    "print(\"level =\",level)\n",
    "print(\"root node\")\n",
    "r_class=Counter(y).most_common(3)\n",
    "print(\"count of \",r_class[0][0],\"=\",r_class[0][1])\n",
    "print(\"count of \",r_class[1][0],\"=\",r_class[1][1])\n",
    "print(\"count of \",r_class[2][0],\"=\",r_class[2][1])\n",
    "print()\n",
    "z=0\n",
    "level+=1\n",
    "DecisionTree(x,y,features,z,level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
